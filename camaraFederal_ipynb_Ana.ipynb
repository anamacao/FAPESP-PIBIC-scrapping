{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anamacao/FAPESP-PIBIC-scrapping/blob/main/camaraFederal_ipynb_Ana.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## camaraFederal.ipynb"
      ],
      "metadata": {
        "id": "7oLyu642lfeS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cOG3jfMsk0Zg"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "from datetime import datetime\n",
        "import sqlite3\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = \"notebook_connected\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
        "}\n",
        "\n",
        "BASE_URL = \"https://www.camara.leg.br/noticias/noticias-institucionais\"\n",
        "print(\"‚úÖ Scraper da C√¢mara (Institucionais) pronto!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYjRURw2mdhp",
        "outputId": "6f0cf210-f13a-4841-a481-9a41d3ee443c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Scraper da C√¢mara (Institucionais) pronto!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATABASE_NAME = \"internet_governance_news.db\"\n",
        "\n",
        "def create_database():\n",
        "    conn = sqlite3.connect(DATABASE_NAME)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS articles (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            title TEXT,\n",
        "            date TEXT,\n",
        "            author TEXT,\n",
        "            url TEXT UNIQUE,\n",
        "            source TEXT\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    print(\"‚úÖ Banco e tabela 'articles' prontos!\")\n",
        "\n",
        "create_database()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLDOiMM2ntM-",
        "outputId": "45b53aa9-450f-4030-d78e-a359f23c3c66"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Banco e tabela 'articles' prontos!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Banco e tabela 'articles' prontos!\n"
      ],
      "metadata": {
        "id": "I48w9FDVqe4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_article(title, date, author, url, source):\n",
        "    conn = sqlite3.connect(DATABASE_NAME)\n",
        "    cursor = conn.cursor()\n",
        "    try:\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO articles (title, date, author, url, source)\n",
        "            VALUES (?, ?, ?, ?, ?)\n",
        "        \"\"\", (title, date, author, url, source))\n",
        "        conn.commit()\n",
        "        return True\n",
        "    except sqlite3.IntegrityError:\n",
        "        return False\n",
        "    finally:\n",
        "        conn.close()"
      ],
      "metadata": {
        "id": "u1a9DrdcqjMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "def load_articles_from_db():\n",
        "    conn = sqlite3.connect(DATABASE_NAME)\n",
        "    df = pd.read_sql(\"\"\"\n",
        "        SELECT *\n",
        "        FROM articles\n",
        "        ORDER BY date DESC\n",
        "    \"\"\", conn)\n",
        "    conn.close()\n",
        "    return df\n",
        "\n",
        "df_db = load_articles_from_db()\n",
        "display(df_db.head())\n",
        "print(f\"üì¶ Total no banco: {len(df_db)} registros\")"
      ],
      "metadata": {
        "id": "Uwu2FmfTvJOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "noticias = []\n",
        "TOTAL_PAGES = 78\n",
        "\n",
        "for pagina in range(TOTAL_PAGES, 0, -1):\n",
        "    url = montar_url(pagina)\n",
        "    print(f\"üìÑ Coletando p√°gina {pagina}: {url}\")\n",
        "\n",
        "    r = requests.get(url, headers=HEADERS, timeout=10)\n",
        "    if r.status_code != 200:\n",
        "        print(\"‚ö†Ô∏è Erro ao acessar p√°gina\")\n",
        "        continue\n",
        "\n",
        "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "    # ===== Seletores adaptados para NOT√çCIAS INSTITUCIONAIS\n",
        "    itens = soup.select(\"li.l-lista-noticias__item\")\n",
        "    print(f\"   {len(itens)} not√≠cias encontradas\")\n",
        "\n",
        "    for item in itens:\n",
        "        artigo = item.select_one(\"article.g-chamada\")\n",
        "        if not artigo:\n",
        "            continue\n",
        "\n",
        "        # t√≠tulo & link\n",
        "        titulo_tag = artigo.select_one(\".g-chamada__titulo a\")\n",
        "        if not titulo_tag:\n",
        "            continue\n",
        "\n",
        "        titulo = titulo_tag.get_text(strip=True)\n",
        "        link = titulo_tag[\"href\"]\n",
        "\n",
        "        # data e hora\n",
        "        date_tag = artigo.select_one(\".g-artigo__data-hora\")\n",
        "        data_raw = date_tag.get_text(strip=True) if date_tag else \"NA\"\n",
        "\n",
        "        # extrai texto\n",
        "        paragrafos = extrair_paragrafos(link)\n",
        "\n",
        "        # acumula\n",
        "        noticias.append({\n",
        "            \"titulo\": titulo,\n",
        "            \"data\": data_raw,\n",
        "            \"link\": link,\n",
        "            \"paragrafos\": \" || \".join(paragrafos),\n",
        "            \"fonte\": \"C√¢mara dos Deputados\"\n",
        "        })\n",
        "\n",
        "        # grava no banco\n",
        "        insert_article(\n",
        "            title=titulo,\n",
        "            date=data_raw,\n",
        "            author=\"Ag√™ncia C√¢mara\",\n",
        "            url=link,\n",
        "            source=\"C√¢mara dos Deputados\"\n",
        "        )\n",
        "\n",
        "    time.sleep(1)\n",
        "\n",
        "print(f\"\\n‚úÖ Total coletado: {len(noticias)} not√≠cias\")\n",
        "\n",
        "df_camara = pd.DataFrame(noticias)\n",
        "display(df_camara.head())"
      ],
      "metadata": {
        "id": "lTGPqr_byDAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_articles():\n",
        "    conn = sqlite3.connect(DATABASE_NAME)\n",
        "    df = pd.read_sql(\"\"\"\n",
        "        SELECT * FROM articles\n",
        "        ORDER BY date DESC\n",
        "    \"\"\", conn)\n",
        "    conn.close()\n",
        "    return df\n",
        "\n",
        "df_db = load_articles()\n",
        "print(f\"üì¶ Total no banco: {len(df_db)} registros\")\n",
        "display(df_db.head(20))"
      ],
      "metadata": {
        "id": "JlBTLmVLyOvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = ['digital', 'internet', 'IA', 'tecnologia', 'dados', 'privacidade']\n",
        "pattern = r'|'.join(keywords)\n",
        "\n",
        "df_filt = df_camara[\n",
        "    df_camara['titulo'].str.contains(pattern, case=False, na=False, regex=True) |\n",
        "    df_camara['paragrafos'].str.contains(pattern, case=False, na=False, regex=True)\n",
        "].copy()\n",
        "\n",
        "print(f\"{len(df_filt)} not√≠cias filtradas (de {len(df_camara)})\")\n",
        "display(df_filt.head())"
      ],
      "metadata": {
        "id": "LoWT4xriyHgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_charts(df):\n",
        "    if df.empty:\n",
        "        print(\"‚ùå Sem dados para gr√°ficos\")\n",
        "        return\n",
        "\n",
        "    # ------------------------------\n",
        "    # Top 15\n",
        "    # ------------------------------\n",
        "    top15 = df.head(15).copy()\n",
        "    top15['rank'] = range(1, len(top15) + 1)\n",
        "\n",
        "    fig1 = px.bar(\n",
        "        top15,\n",
        "        x='rank',\n",
        "        y='title',\n",
        "        orientation='h',\n",
        "        title='Top 15 Not√≠cias ‚Äì Internet Governance'\n",
        "    )\n",
        "    fig1.update_layout(height=600)\n",
        "    fig1.show()\n",
        "\n",
        "    # ------------------------------\n",
        "    # Pizza por Fonte (BANCO)\n",
        "    # ------------------------------\n",
        "    # Fonte\n",
        "    source_count = df[\"source\"].value_counts().reset_index()\n",
        "    source_count.columns = [\"source\", \"count\"]\n",
        "\n",
        "    fig2 = px.pie(\n",
        "        source_count,\n",
        "        names=\"source\",\n",
        "        values=\"count\",\n",
        "        title=\"Distribui√ß√£o por Fonte\"\n",
        "    )\n",
        "    fig2.show()\n",
        "\n",
        "    # ------------------------------\n",
        "    # Nuvem de Palavras\n",
        "    # ------------------------------\n",
        "    text = ' '.join(df['title'].astype(str)).lower()\n",
        "    words = re.findall(r'\\b\\w{4,}\\b', text)\n",
        "\n",
        "    wc = (\n",
        "        pd.Series(words)\n",
        "        .value_counts()\n",
        "        .head(20)\n",
        "        .reset_index()\n",
        "    )\n",
        "    wc.columns = ['palavra', 'freq']\n",
        "\n",
        "    fig3 = px.treemap(\n",
        "        wc,\n",
        "        path=['palavra'],\n",
        "        values='freq',\n",
        "        title='Nuvem de Palavras ‚Äì T√≠tulos'\n",
        "    )\n",
        "    fig3.show()"
      ],
      "metadata": {
        "id": "bOM-b2mCyLBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "428267f0"
      },
      "source": [
        "plot_charts(df_db)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}